import csv
import hashlib
import json
import uuid
from typing import Any

from django.http import Http404, HttpResponse
from django.shortcuts import get_object_or_404
from ninja import File, NinjaAPI, Schema
from ninja.files import UploadedFile

from app.models import Evaluation, StandardAnswer

api = NinjaAPI()


class EvaluationRequest(Schema):
    """Schema for evaluation request.

    Attributes:
    ----------
    exp_id : str
        The ID of the test project.
    question_id : str | None
        The ID of the question (optional).
    test_question : str
        The text of the test question.
    question_source : str
        The source of the question.
    bot_response : str
        The response generated by the bot.
    """
    exp_id: str
    question_id: str | None = None
    test_question: str
    question_source: str
    bot_response: str


class EvaluationResponse(Schema):
    """Schema for evaluation response.

    Attributes:
    ----------
    question_id : str
        The ID of the question.
    exp_id : str
        The ID of the test project.
    test_question : str
        The text of the test question.
    bot_response : str
        The response generated by the bot.
    question_source : str
        The source of the question.
    standard_answer : str
        The standard answer for the question.
    difficulty : int
        The difficulty level of the question.
    accuracy : int
        The accuracy score of the bot's response.
    relevance : int
        The relevance score of the bot's response.
    logic : int
        The logic score of the bot's response.
    conciseness : int
        The conciseness score of the bot's response.
    language_quality : int
        The language quality score of the bot's response.
    total_score : int
        The total score of the bot's response.
    """
    question_id: str
    exp_id: str
    test_question: str
    bot_response: str
    question_source: str
    standard_answer: str
    difficulty: int
    accuracy: int
    relevance: int
    logic: int
    conciseness: int
    language_quality: int
    total_score: int


def generate_question_id() -> str:
    """Generate a unique question ID."""
    random_string = str(uuid.uuid4())
    return hashlib.md5(random_string.encode()).hexdigest()[:6]  # noqa: S324


def evaluate_response(bot_response: str, standard_answer: str) -> dict[str, int]:
    """Evaluate the bot's response against the standard answer.

    Parameters
    ----------
    bot_response : str
        The response generated by the bot.
    standard_answer : str
        The standard answer for the question.

    Returns:
    -------
    dict[str, int]
        A dictionary containing evaluation scores.
    """
    accuracy = 5 if standard_answer in bot_response else 3
    relevance = logic = conciseness = language_quality = 4
    total_score = sum([accuracy, relevance, logic, conciseness, language_quality])
    return {
        "accuracy": accuracy,
        "relevance": relevance,
        "logic": logic,
        "conciseness": conciseness,
        "language_quality": language_quality,
        "total_score": total_score,
    }


@api.post("/evaluate", response=EvaluationResponse)
def evaluate(request: HttpResponse, data: EvaluationRequest) -> EvaluationResponse:
    """Evaluate a single test question.

    Parameters
    ----------
    request : Any
        The HTTP request object.
    data : EvaluationRequest
        The evaluation request data.

    Returns:
    -------
    EvaluationResponse
        The evaluation result.
    """
    _ = request
    question_id = data.question_id or generate_question_id()
    try:
        standard_answer_obj = StandardAnswer.objects.get(source=data.question_source)
    except StandardAnswer.DoesNotExist:
        raise Http404(f"No standard answer : {data.question_source}")

    result = evaluate_response(data.bot_response, standard_answer_obj.content)
    difficulty = 3

    Evaluation.objects.create(
        question_id=question_id,
        exp_id=data.exp_id,
        test_question=data.test_question,
        bot_response=data.bot_response,
        question_source=data.question_source,
        standard_answer=standard_answer_obj.content,
        difficulty=difficulty,
        **result,
    )

    return EvaluationResponse(
        question_id=question_id,
        exp_id=data.exp_id,
        test_question=data.test_question,
        bot_response=data.bot_response,
        question_source=data.question_source,
        standard_answer=standard_answer_obj.content,
        difficulty=difficulty,
        **result,
    )


@api.post("/evaluate/batch", response=list[EvaluationResponse])
def batch_evaluate(request: HttpResponse, data: list[EvaluationRequest]) -> list[EvaluationResponse]:
    """Evaluate a batch of test questions.

    Parameters
    ----------
    request : Any
        The HTTP request object.
    data : list[EvaluationRequest]
        A list of evaluation request data.

    Returns:
    -------
    list[EvaluationResponse]
        A list of evaluation results.
    """
    return [evaluate(request, item) for item in data]


@api.get("/evaluations", response=dict[str, EvaluationResponse])
def get_all_evaluations(request: HttpResponse) -> dict[str, EvaluationResponse]:
    """Retrieve all evaluations.

    Parameters
    ----------
    request : Any
        The HTTP request object.

    Returns:
    -------
    dict[str, EvaluationResponse]
        A dictionary of all evaluations keyed by question ID.
    """
    _ = request
    evaluations = Evaluation.objects.all()
    return {evaluation.question_id: EvaluationResponse(**evaluation.__dict__) for evaluation in evaluations}


@api.get("/evaluation/{question_id}", response=EvaluationResponse)
def get_evaluation(request: HttpResponse, question_id: str) -> EvaluationResponse:
    """Retrieve a specific evaluation by question ID.

    Parameters
    ----------
    request : Any
        The HTTP request object.
    question_id : str
        The ID of the question.

    Returns:
    -------
    EvaluationResponse
        The evaluation result.
    """
    _ = request
    evaluation = get_object_or_404(Evaluation, question_id=question_id)
    return EvaluationResponse(**evaluation.__dict__)


@api.get("/project/{project_id}/evaluations", response=list[EvaluationResponse])
def get_project_evaluations(request: HttpResponse, project_id: str) -> list[EvaluationResponse]:
    """Retrieve evaluations for a specific project.

    Parameters
    ----------
    request : Any
        The HTTP request object.
    project_id : str
        The ID of the project.

    Returns:
    -------
    list[EvaluationResponse]
        A list of evaluation results for the project.
    """
    _ = request
    evaluations = Evaluation.objects.filter(exp_id=project_id)
    return [EvaluationResponse(**evaluation.__dict__) for evaluation in evaluations]


@api.get("/project/{project_id}/export_csv")
def export_project_csv(request: HttpResponse, project_id: str) -> HttpResponse:
    """Export evaluations for a project as a CSV file.

    Parameters
    ----------
    request : Any
        The HTTP request object.
    project_id : str
        The ID of the project.

    Returns:
    -------
    HttpResponse
        A response containing the CSV file.
    """
    _ = request
    evaluations = Evaluation.objects.filter(exp_id=project_id)
    if not evaluations.exists():
        raise Http404(f"未找到測試項目 {project_id} 的資料")

    response = HttpResponse(content_type="text/csv")
    response["Content-Disposition"] = f'attachment; filename="project_{project_id}_evaluations.csv"'

    writer = csv.writer(response)
    writer.writerow([
        "question_id", "exp_id", "test_question", "bot_response",
        "question_source", "standard_answer", "difficulty",
        "accuracy", "relevance", "logic", "conciseness", "language_quality",
        "total_score", "created_at",
    ])

    for evaluation in evaluations:
        writer.writerow([
            evaluation.question_id,
            evaluation.exp_id,
            evaluation.test_question,
            evaluation.bot_response,
            evaluation.question_source,
            evaluation.standard_answer,
            evaluation.difficulty,
            evaluation.accuracy,
            evaluation.relevance,
            evaluation.logic,
            evaluation.conciseness,
            evaluation.language_quality,
            evaluation.total_score,
            evaluation.created_at.isoformat(),
        ])

    return response


@api.post("/upload_json", response=list[dict[str, str]])
def upload_json(request: HttpResponse, file: UploadedFile = File(...), project_id: str | None = None) -> list[dict[str, str]]:
    """Upload a JSON file and process its content.

    Parameters
    ----------
    request : Any
        The HTTP request object.
    file : UploadedFile
        The uploaded JSON file.
    project_id : str | None
        The ID of the project (optional).

    Returns:
    -------
    list[dict[str, str]]
        A list of processed results.
    """
    _ = request
    try:
        raw = file.read().decode("utf-8")
        data = json.loads(raw)
    except Exception as e:
        raise Http404(f"無法解析 JSON 檔案:{e}")

    results = []
    for item in data:
        question_id = item.get("question_id") or generate_question_id()
        question = item.get("question")
        response = item.get("response")
        sources = item.get("sources", [])

        if not (question and response and sources):
            continue  # Skip incomplete data

        source_title = sources[0].get("title", "")
        reference = sources[0].get("content", "")

        try:
            standard_answer_obj = StandardAnswer.objects.get(source=source_title)
            standard_answer = standard_answer_obj.content
        except StandardAnswer.DoesNotExist:
            standard_answer = reference  # Fallback to provided content

        score = evaluate_response(response, standard_answer)

        Evaluation.objects.update_or_create(
            question_id=question_id,
            defaults={
                "exp_id": project_id or "uploaded_project",
                "test_question": question,
                "bot_response": response,
                "question_source": source_title,
                "standard_answer": standard_answer,
                "difficulty": 3,
                **score,
            },
        )

        results.append({
            "question_id": question_id,
            "total_score": str(score["total_score"]),
        })

    return results
